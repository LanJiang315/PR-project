#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2021/5/14 下午12:15
# @Author  : Lan Jiang
# @File    : bert_embs.py

from sentence_transformers import SentenceTransformer, util
import os
import pandas as pd
import argparse
import pickle


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_dir", type=str, default="../../Dataset/shopee-product-matching/")
    parser.add_argument("--cache_dir", type=str, default="../../Dataset/shopee-product-matching/aux_files")
    parser.add_argument("--model_name", type=str, default="paraphrase-distilroberta-base-v1")
    args = parser.parse_args()

    # get the representations generated by pre-trained models
    model = SentenceTransformer(args.model_name)
    data = pd.read_csv(os.path.join(args.data_dir, "train.csv"))
    titles = data['title'].tolist()
    titles_embeddings = model.encode(titles)

    # save to cache files
    with open(os.path.join(args.cache_dir, "%s_emb.pickle" % args.model_name), "wb") as f:
        pickle.dump(titles_embeddings, f)
    print("save embeddings produced by %s over." % args.model_name)

    # # save
    # cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]
    # top_results = torch.topk(cos_scores, k=top_k)





