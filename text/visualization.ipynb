{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% read data\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../../train.csv\")\n",
    "titles = data['title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import textfeatures\n",
    "def extract_title_features(df_prep):\n",
    "    '''Extracts features from the unprocessed title column.'''\n",
    "    \n",
    "    # Extract Features\n",
    "    df_prep = textfeatures.word_count(df_prep, \"title\", \"word_count\")\n",
    "    df_prep = textfeatures.char_count(df_prep, \"title\", \"char_count\")\n",
    "    df_prep = textfeatures.avg_word_length(df_prep, \"title\", \"avg_word_length\")\n",
    "    df_prep = textfeatures.stopwords_count(df_prep, \"title\", \"stopwords_count\")\n",
    "    df_prep = textfeatures.numerics_count(df_prep, \"title\", \"numerics_count\")\n",
    "    \n",
    "    return df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_colors = [\"#EDAC54\", \"#F4C5B7\", \"#DD7555\", \"#B95F18\", \"#475A20\"]\n",
    "\n",
    "train_df_prep = extract_title_features(df_prep=data)\n",
    "title_features = ['word_count', 'char_count', 'avg_word_length',\n",
    "                  'stopwords_count']\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(25, 4), squeeze=False)\n",
    "# plt.suptitle(f\"Title : Features Extracted\", fontsize=20)\n",
    "rows = [0, 0, 0, 0]\n",
    "cols = [0, 1, 2, 3]\n",
    "# axs[1,2].set_visible(False)\n",
    "\n",
    "for k, (name, i, j) in enumerate(zip(title_features, rows, cols)):\n",
    "    sns.kdeplot(train_df_prep[name], ax=axs[i, j], color=my_colors[k],\n",
    "                shade=\"fill\", lw=3)\n",
    "    axs[i, j].set_title(name, fontsize=15)\n",
    "    axs[i, j].set_xlabel(\"\", fontsize=16)\n",
    "    axs[i, j].set_ylabel(\"\", fontsize=16)\n",
    "\n",
    "\n",
    "fig.savefig('count.eps',dpi=600,format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_corpus():\n",
    "    aux_file = os.path.join(\"../../tok_corpus.pickle\")\n",
    "    if not os.path.exists(aux_file):\n",
    "        print(\"building corpus matrix from raw data...\")\n",
    "        corpus = build_corpus(args.data_dir)\n",
    "        if not os.path.exists(args.cache_dir):\n",
    "            os.mkdir(args.cache_dir)\n",
    "        with open(aux_file, \"wb\") as f:\n",
    "            pickle.dump(corpus, f)\n",
    "        print(\"building corpus over.\")\n",
    "    else:\n",
    "        print(\"load weights matrix from cached file: \", aux_file)\n",
    "        with open(aux_file, \"rb\") as f:\n",
    "            corpus = pickle.load(f)\n",
    "        print(\"load over.\")\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corpus = load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_prep = pd.DataFrame({\"title\": [' '.join(item) for item in corpus]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../train.csv\")\n",
    "data['std_titles'] = [' '.join(item) for item in corpus]\n",
    "data.to_csv(\"../../std_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def show_values_on_bars(axs, h_v=\"v\", space=0.4):\n",
    "    '''Plots the value at the end of the a seaborn barplot.\n",
    "    axs: the ax of the plot\\n\",\n",
    "    h_v: weather or not the barplot is vertical/ horizontal\n",
    "    '''\n",
    "    def _show_on_single_plot(ax):\n",
    "        if h_v == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_height())\n",
    "                ax.text(_x, _y, format(value, ','), ha=\"center\")\n",
    "        elif h_v == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_width())\n",
    "                ax.text(_x, _y, format(value, ','), ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bag of words from the title\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "title_prep = df_prep[\"title\"].values.astype('U')\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(title_prep)\n",
    "\n",
    "bag_of_words = pd.DataFrame({'word' : vectorizer.vocabulary_.keys(),\n",
    "                             'freq' : vectorizer.vocabulary_.values()})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "plot = sns.barplot(data=bag_of_words.head(10).sort_values('freq', ascending=False),\n",
    "                   y=\"word\", x=\"freq\", color=\"blue\")\n",
    "show_values_on_bars(plot, h_v=\"h\", space=0.3)\n",
    "# plt.title(\"Example of words & frequencies\", fontsize=20)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks([],)\n",
    "plt.xlabel(\"Frequency\", fontsize=16)\n",
    "plt.ylabel(\"\", fontsize=16)\n",
    "\n",
    "plt.savefig('freq.eps',dpi=600,format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS as stopwords_wc\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "# Get all titles\n",
    "text_for_wc = \" \".join(title for title in df_prep[\"title\"])\n",
    "\n",
    "# Wordcloud\n",
    "# font_path = \"../input/shopee-preprocessed-data/ACETONE.otf\"\n",
    "stopwords_wc = set(stopwords_wc)\n",
    "# stopwords_wc.update([\"yes\"])\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords_wc, \n",
    "                      max_words=4000,\n",
    "                      max_font_size=200, random_state=42,\n",
    "                      width=1600, height=800,\n",
    "                      colormap = \"copper\")\n",
    "wordcloud.generate(text_for_wc)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('wordcloud.eps',dpi=200,format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get count of values on each group\n",
    "train_df=data\n",
    "groups_df = train_df[\"label_group\"].value_counts().reset_index()\n",
    "groups_df.columns = [\"group\", \"count\"]\n",
    "\n",
    "# Print info\n",
    "print(\"No. of unique groups: {:,}\".format(len(groups_df)), \"\\n\" +\n",
    "      \"Max no. of apparitions in 1 group: {}\".format(groups_df[\"count\"].max()), \"\\n\" +\n",
    "      \"Min no. of apparitions in 1 group: {}\".format(groups_df[\"count\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(24, 8))\n",
    "# plt.bar(groups_df.iloc[:10][\"group\"].to_numpy(), groups_df.iloc[:10][\"count\"].to_numpy(), facecolor = 'lightskyblue', edgecolor = 'white')\n",
    "plt.bar(a, b, facecolor = 'lightskyblue', edgecolor = 'white')\n",
    "plt.title(\"Group Count Distribution\", fontsize=20)\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Group ID\", fontsize=16)\n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of values on each group\n",
    "train_df=data\n",
    "groups_df = train_df[\"label_group\"].value_counts().reset_index()\n",
    "groups_df.columns = [\"group\", \"count\"]\n",
    "\n",
    "# Print info\n",
    "print(\"No. of unique groups: {:,}\".format(len(groups_df)), \"\\n\" +\n",
    "      \"Max no. of apparitions in 1 group: {}\".format(groups_df[\"count\"].max()), \"\\n\" +\n",
    "      \"Min no. of apparitions in 1 group: {}\".format(groups_df[\"count\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "a=[str(item) for item in groups_df[\"group\"].to_numpy()]\n",
    "b=groups_df[\"count\"].to_numpy()\n",
    "np.sum(b), np.sum(b[b>5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.bar(groups_df.iloc[:10][\"group\"].to_numpy(), groups_df.iloc[:10][\"count\"].to_numpy(), facecolor = 'lightskyblue', edgecolor = 'white')\n",
    "# plt.bar(a, b, facecolor = 'lightskyblue', edgecolor = 'white')\n",
    "plt.title(\"Group Count Distribution\", fontsize=20)\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Group ID\", fontsize=16)\n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "plt.savefig('../../image4paper/label_count.eps',dpi=200,format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of apparitions per image\n",
    "image_count = train_df[\"image\"].value_counts().reset_index()\n",
    "image_count.columns = [\"image\", \"count\"]\n",
    "image_count_duplicates = image_count[image_count[\"count\"] > 1]\n",
    "print(\"Total no. of images with duplicates: {:,}\".format(len(image_count_duplicates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "plt.bar(x=image_count_duplicates.iloc[::16][\"image\"],\n",
    "        height=image_count_duplicates.iloc[::16][\"count\"],\n",
    "        facecolor = 'yellowgreen', edgecolor = 'white')\n",
    "plt.title(\"Duplicated Images: How many apparitions?\", fontsize=20)\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Image ID\", fontsize=16)\n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "plt.savefig('../../image4paper/duplicate.eps',dpi=200,format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bertviz import head_view\n",
    "from transformers import XLMTokenizer, XLMModel\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../Dataset/shopee-product-matching/split_data/new_test.csv\")\n",
    "std_titles = data['std_title'].tolist()\n",
    "titles = data['title'].tolist()\n",
    "ground_true_list = []\n",
    "label_list = data['label_group'].to_numpy()\n",
    "for i in range(len(label_list)):\n",
    "    label = label_list[i]\n",
    "    ground_true = 1 * (label_list == label)\n",
    "    ground_true_list.append(ground_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_model_pred(method, include_self=False):\n",
    "    file_name = \"%s_pred%s.pickle\" % (method, \"_include_self\" if include_self else \"\")\n",
    "    with open(os.path.join(\"../../tmp/shopee\", file_name), \"rb\") as f:\n",
    "        pred_list = pickle.load(f)\n",
    "\n",
    "    return np.array(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_pred = load_single_model_pred(\"bm25\", include_self=True)\n",
    "pca_pred = load_single_model_pred(\"pca\", include_self=True)\n",
    "bert_pred = load_single_model_pred(\"bert\", include_self=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BM25错例分析\n",
    "bm25_wrong = bm25_pred == ground_true_list\n",
    "row, col = np.where(wrong == False)\n",
    "for r, c in zip(row, col):\n",
    "    print(\"t1: \", std_titles[r])\n",
    "    print(\"t2: \", std_titles[c])\n",
    "    print(\"label: \", ground_true_list[r][c], \" output: \", bm25_pred[r][c], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca错例分析\n",
    "pca_wrong = pca_pred == ground_true_list\n",
    "row, col = np.where(wrong == False)\n",
    "for r, c in zip(row, col):\n",
    "    print(\"t1: \", std_titles[r])\n",
    "    print(\"t2: \", std_titles[c])\n",
    "    print(\"label: \", ground_true_list[r][c], \" output: \", pca_pred[r][c], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT错例分析\n",
    "bert_wrong = bert_pred == ground_true_list\n",
    "row, col = np.where(wrong == False)\n",
    "for r, c in zip(row, col):\n",
    "    print(\"t1: \", std_titles[r])\n",
    "    print(\"t2: \", std_titles[c])\n",
    "    print(\"label: \", ground_true_list[r][c], \" output: \", bert_pred[r][c], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_head_view(model, tokenizer, sentence_a, sentence_b=None, layer=None, heads=None):\n",
    "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    if sentence_b:\n",
    "        attention = model(input_ids)[-1]\n",
    "        sentence_b_start = input_ids[0].tolist().index(1)\n",
    "    else:\n",
    "        attention = model(input_ids)[-1]\n",
    "        sentence_b_start = None\n",
    "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)    \n",
    "    head_view(attention, tokens, sentence_b_start, layer=layer, heads=heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "model_version = '../../tmp/shopee/cahya/distilbert-base-indonesian/0_Transformer/'\n",
    "model = DistilBertModel.from_pretrained(model_version, output_attentions=True, from_tf=False)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT正例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_wrong = bm25_pred == ground_true_list\n",
    "pca_wrong = pca_pred == ground_true_list\n",
    "bert_wrong = bert_pred == ground_true_list\n",
    "\n",
    "row, col = np.where((bm25_wrong==False) & (pca_wrong==False) & (bert_wrong==False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title a:  tzuki instant whitening body soap\n",
      "title b:  sabun tzuki original\n"
     ]
    }
   ],
   "source": [
    "index = 10\n",
    "r, c = row[index], col[index]\n",
    "title_a = std_titles[r]\n",
    "title_b = std_titles[c]\n",
    "print(\"title a: \", title_a)\n",
    "print(\"title b: \", title_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id='bertviz-53dddc856b294e32b9a6ea289fbf82b2'>\n",
       "            <span style=\"user-select:none\">\n",
       "                Layer: <select id=\"layer\"></select>\n",
       "                Attention: <select id=\"filter\"><option value=\"0\">All</option>\n",
       "<option value=\"1\">Sentence A -> Sentence A</option>\n",
       "<option value=\"2\">Sentence B -> Sentence B</option>\n",
       "<option value=\"3\">Sentence A -> Sentence B</option>\n",
       "<option value=\"4\">Sentence B -> Sentence A</option></select>\n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/**\n",
       " * @fileoverview Transformer Visualization D3 javascript code.\n",
       " *\n",
       " *\n",
       " *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
       " *\n",
       " * Change log:\n",
       " *\n",
       " * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n",
       " * 12/29/20  Jesse Vig   Significant refactor.\n",
       " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
       " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
       " * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n",
       " **/\n",
       "\n",
       "require.config({\n",
       "  paths: {\n",
       "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
       "    jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "  }\n",
       "});\n",
       "\n",
       "requirejs(['jquery', 'd3'], function ($, d3) {\n",
       "\n",
       "    const params = {\"attention\": [{\"name\": \"All\", \"attn\": [[[[0.08006226271390915, 0.0365225188434124, 0.07422703504562378, 0.031202200800180435, 0.0199290681630373, 0.049372076988220215, 0.018967194482684135, 0.042732901871204376, 0.024416103959083557, 0.06596794724464417, 0.03769360110163689, 0.024998050183057785, 0.028687607496976852, 0.04744672775268555, 0.03769419714808464, 0.05760107934474945, 0.0421784408390522, 0.05821690335869789, 0.07555897533893585, 0.039988722652196884, 0.10653640329837799], [0.03213903307914734, 0.062316011637449265, 0.2695356607437134, 0.07444305717945099, 0.00748042669147253, 0.04328440874814987, 0.08552691340446472, 0.01857289858162403, 0.07959835976362228, 0.03584286570549011, 0.01307928841561079, 0.05277300998568535, 0.009623691439628601, 0.008549492806196213, 0.02989029698073864, 0.013179121538996696, 0.00665381271392107, 0.040017735213041306, 0.041987039148807526, 0.06520207226276398, 0.010304776951670647], [0.040450677275657654, 0.06199944019317627, 0.04349501430988312, 0.029606912285089493, 0.07158315926790237, 0.11798255890607834, 0.0716976672410965, 0.028631191700696945, 0.033175401389598846, 0.08194276690483093, 0.03443170338869095, 0.04284624010324478, 0.09772181510925293, 0.040709611028432846, 0.037378959357738495, 0.035600606352090836, 0.02852458879351616, 0.02034010738134384, 0.05342341959476471, 0.010406211018562317, 0.018052009865641594], [0.016107693314552307, 0.02727372758090496, 0.02316606044769287, 0.29640984535217285, 0.1490022987127304, 0.048962436616420746, 0.1777726411819458, 0.05580868199467659, 0.006717967335134745, 0.011158282868564129, 0.032976578921079636, 0.0038885718677192926, 0.022724004462361336, 0.026664994657039642, 0.003584221936762333, 0.009234649129211903, 0.007193584460765123, 0.02606379985809326, 0.05005713552236557, 0.003092333674430847, 0.0021404805593192577], [0.007054682821035385, 0.009680990129709244, 0.06382901221513748, 0.3837033808231354, 0.021439000964164734, 0.029145102947950363, 0.040813859552145004, 0.07449715584516525, 0.05445048585534096, 0.016386020928621292, 0.02931126020848751, 0.024156857281923294, 0.015310464426875114, 0.030382853001356125, 0.04300323873758316, 0.014588750898838043, 0.01099935732781887, 0.06624359637498856, 0.009021623060107231, 0.046646375209093094, 0.009335883893072605], [0.022415732964873314, 0.01360021997243166, 0.00770760839805007, 0.06380607932806015, 0.02205793745815754, 0.051703572273254395, 0.3590724468231201, 0.055565398186445236, 0.10916128754615784, 0.00889043789356947, 0.013077238574624062, 0.04329223930835724, 0.02738577499985695, 0.016650989651679993, 0.04832959547638893, 0.004009168595075607, 0.04716455563902855, 0.017852632328867912, 0.03037748672068119, 0.024560436606407166, 0.013319261372089386], [0.019540442153811455, 0.016566546633839607, 0.020756077021360397, 0.11673256754875183, 0.01815478317439556, 0.04715242609381676, 0.14632093906402588, 0.08725502341985703, 0.07825808227062225, 0.10849633067846298, 0.03435729071497917, 0.029475510120391846, 0.0713047906756401, 0.025469880551099777, 0.017804937437176704, 0.011414607055485249, 0.00991860218346119, 0.08310718834400177, 0.014902448281645775, 0.02888031303882599, 0.014131198637187481], [0.04243902117013931, 0.003005426377058029, 0.008135204203426838, 0.0046359277330338955, 0.0013196096988394856, 0.013587064109742641, 0.0573221817612648, 0.049879733473062515, 0.2676267623901367, 0.2482290118932724, 0.03063211403787136, 0.11909283697605133, 0.02425161376595497, 0.02074114978313446, 0.07021778076887131, 0.02083568274974823, 0.0020766633097082376, 0.00427231565117836, 0.001846500439569354, 0.0017874413169920444, 0.008065947331488132], [0.016366325318813324, 0.05518694967031479, 0.020351817831397057, 0.01420067623257637, 0.03168278932571411, 0.009556608274579048, 0.04625196009874344, 0.05903595685958862, 0.07478836178779602, 0.16183938086032867, 0.16879940032958984, 0.048590365797281265, 0.10062167793512344, 0.03141850605607033, 0.013104808516800404, 0.010119583457708359, 0.004387043882161379, 0.12055464088916779, 0.01164333801716566, 0.001156895188614726, 0.000342811516020447], [0.01392302755266428, 0.0056203934364020824, 0.00905035063624382, 0.0013996411580592394, 0.001268285559490323, 0.007885046303272247, 0.006058005150407553, 0.05985299497842789, 0.01809590868651867, 0.0412861593067646, 0.6741955280303955, 0.05714917555451393, 0.004235742148011923, 0.06502003222703934, 0.0037374591920524836, 0.0022896218579262495, 0.005007828585803509, 0.015716874971985817, 0.0053931367583572865, 0.0028059575706720352, 8.840837836032733e-06], [0.06495491415262222, 0.002299294341355562, 0.004711423069238663, 0.005585942883044481, 0.0010995225748047233, 0.012485307641327381, 0.03550463542342186, 0.0160541795194149, 0.06939929723739624, 0.052524831146001816, 0.03941333666443825, 0.3415815532207489, 0.10810364037752151, 0.047176916152238846, 0.12288489192724228, 0.04622836783528328, 0.002193775027990341, 0.008913475088775158, 0.005648355931043625, 0.003376452950760722, 0.009859930723905563], [0.019689390435814857, 0.022952593863010406, 0.009359539486467838, 0.013363497331738472, 0.024958040565252304, 0.007262803614139557, 0.03933143988251686, 0.016087675467133522, 0.017780015245079994, 0.008718730881810188, 0.04541827738285065, 0.066990427672863, 0.4246184825897217, 0.06434553116559982, 0.038160644471645355, 0.01697709411382675, 0.003944677300751209, 0.13519027829170227, 0.020553069189190865, 0.002600239124149084, 0.0016975620528683066], [0.013767286203801632, 0.013651077635586262, 0.040247052907943726, 0.03550070524215698, 0.009080254472792149, 0.0066649429500103, 0.016666796058416367, 0.0044578611850738525, 0.010002726688981056, 0.01748996414244175, 0.006015045568346977, 0.026243604719638824, 0.17404311895370483, 0.022040246054530144, 0.04901743307709694, 0.15146388113498688, 0.05092085897922516, 0.08674586564302444, 0.2154950648546219, 0.032515641301870346, 0.017970513552427292], [0.051269110292196274, 0.0015311639290302992, 0.002397255040705204, 0.005586958955973387, 0.0007968119462020695, 0.008946647867560387, 0.02916616201400757, 0.01263914443552494, 0.06220092624425888, 0.020507121458649635, 0.012095440179109573, 0.10476147383451462, 0.06189524754881859, 0.05581076070666313, 0.39716851711273193, 0.13087008893489838, 0.00502784363925457, 0.010410653427243233, 0.0028932495042681694, 0.002526493975892663, 0.021499067544937134], [0.020333919674158096, 0.03330362215638161, 0.006077475380152464, 0.015583967790007591, 0.019440095871686935, 0.0070664240047335625, 0.03687935322523117, 0.021704554557800293, 0.01723562180995941, 0.009259145706892014, 0.049359578639268875, 0.020250722765922546, 0.12456228584051132, 0.06257517635822296, 0.06234312430024147, 0.06300213187932968, 0.016536597162485123, 0.37965157628059387, 0.029337361454963684, 0.003067311830818653, 0.0024300061631947756], [0.017896225675940514, 0.0066642300225794315, 0.0030889776535332203, 0.017208490520715714, 0.007738600950688124, 0.006751250475645065, 0.00283587328158319, 0.011718898080289364, 0.017872491851449013, 0.01202873233705759, 0.015750592574477196, 0.021870067343115807, 0.0150529183447361, 0.020454086363315582, 0.05627402290701866, 0.03332468494772911, 0.4948222041130066, 0.14027142524719238, 0.012934714555740356, 0.06835481524467468, 0.017086699604988098], [0.011663597077131271, 0.03572980314493179, 0.007133889943361282, 0.02584887482225895, 0.004072907846421003, 0.009281536564230919, 0.06598439812660217, 0.03205060958862305, 0.00566859683021903, 0.0013980481307953596, 0.06522106379270554, 0.01683313399553299, 0.0485197938978672, 0.049772344529628754, 0.014325394295156002, 0.012541897594928741, 0.028700457885861397, 0.33555683493614197, 0.16423369944095612, 0.0533527135848999, 0.012110431678593159], [0.007873862981796265, 0.0019446196965873241, 0.005804111715406179, 0.004750813823193312, 0.0010613882914185524, 0.0034061474725604057, 0.13107554614543915, 0.03264092281460762, 0.005524321924895048, 0.0020976222585886717, 0.0371277742087841, 0.010003536008298397, 0.010527536273002625, 0.0341198705136776, 0.009721075184643269, 0.047461848706007004, 0.014115446247160435, 0.05970084294676781, 0.43804091215133667, 0.08916926383972168, 0.053832557052373886], [0.004435419104993343, 0.005679949186742306, 0.010947010479867458, 0.0023468402214348316, 0.0019103416707366705, 0.013810821808874607, 0.0032165832817554474, 0.010251627303659916, 0.005714055150747299, 0.00021658519108314067, 0.006923987530171871, 0.013614000752568245, 0.025243712589144707, 0.018673326820135117, 0.02035783976316452, 0.009393489919602871, 0.04331210255622864, 0.14028818905353546, 0.03389272838830948, 0.5790628790855408, 0.050708647817373276], [0.014534149318933487, 0.02675764448940754, 0.015395523980259895, 0.0030520427972078323, 0.0185976792126894, 0.01897580176591873, 0.10411034524440765, 0.0736566111445427, 0.006095560733228922, 0.0005590683431364596, 0.017828989773988724, 0.004956078249961138, 0.049657344818115234, 0.06806332617998123, 0.009395797736942768, 0.010073845274746418, 0.019972097128629684, 0.03977798670530319, 0.09163042902946472, 0.03608360514044762, 0.3708260655403137], [0.04068700596690178, 0.006656951270997524, 0.012622825801372528, 0.0011660369345918298, 0.0022362982854247093, 0.0036894753575325012, 0.020436875522136688, 0.23712193965911865, 0.01366255059838295, 0.000611562398262322, 0.07332400232553482, 0.003734575118869543, 0.0021012206561863422, 0.1970277726650238, 0.01638762466609478, 0.005368744023144245, 0.027789536863565445, 0.03243674710392952, 0.025947125628590584, 0.11044375598430634, 0.16654731333255768]], [[0.0005329306004568934, 0.06988796591758728, 0.07654672116041183, 0.02406339719891548, 0.16436150670051575, 0.037245381623506546, 0.04514535889029503, 0.008664055727422237, 0.035931430757045746, 0.002036708639934659, 0.010133113712072372, 0.039358366280794144, 0.02781924419105053, 0.008382589556276798, 0.03525879234075546, 0.06484862416982651, 0.1280764490365982, 0.07131889462471008, 0.10065603256225586, 0.04732659086585045, 0.0024057594127953053], [0.0008260844042524695, 0.055154357105493546, 0.039067041128873825, 0.03493862971663475, 0.10735920071601868, 0.04422512277960777, 0.04888533428311348, 0.042534250766038895, 0.03293191269040108, 0.047907695174217224, 0.043827127665281296, 0.03147651255130768, 0.05874567851424217, 0.041098546236753464, 0.032338038086891174, 0.04328710958361626, 0.06368014216423035, 0.08464560657739639, 0.07108837366104126, 0.03540604189038277, 0.04057729244232178], [0.002508605597540736, 0.04955919459462166, 0.0960075706243515, 0.062385596334934235, 0.11770699918270111, 0.02839035354554653, 0.04415323957800865, 0.0382239893078804, 0.023966018110513687, 0.042584292590618134, 0.03948463127017021, 0.02346329391002655, 0.030041299760341644, 0.041335154324769974, 0.029084615409374237, 0.026041574776172638, 0.04035552963614464, 0.060522064566612244, 0.10074122995138168, 0.05205237865447998, 0.05139230191707611], [0.0008228694787248969, 0.04546241834759712, 0.026981592178344727, 0.04678213968873024, 0.13835085928440094, 0.0620792955160141, 0.07733121514320374, 0.05241791158914566, 0.017018740996718407, 0.05030108615756035, 0.049641046673059464, 0.014044237323105335, 0.04883318394422531, 0.04730510711669922, 0.015672944486141205, 0.053266774863004684, 0.051624707877635956, 0.0706603154540062, 0.0469941683113575, 0.04236621409654617, 0.04204319044947624], [9.173314174404368e-05, 0.1854114532470703, 0.03550231456756592, 0.029890023171901703, 0.24127140641212463, 0.02827354148030281, 0.046205248683691025, 0.04905614256858826, 0.0025886741932481527, 0.005908818915486336, 0.05288803204894066, 0.002538330852985382, 0.03189016878604889, 0.043162550777196884, 0.0022261349949985743, 0.06179739534854889, 0.008244755677878857, 0.1360766440629959, 0.02471032366156578, 0.0037354964297264814, 0.008530800230801105], [0.0006463794852606952, 0.11284641921520233, 0.04473770037293434, 0.0402679443359375, 0.18552660942077637, 0.029310576617717743, 0.06761936843395233, 0.05366965010762215, 0.008060506545007229, 0.0028555127792060375, 0.0451151467859745, 0.007046943064779043, 0.03393419459462166, 0.047986313700675964, 0.009372467175126076, 0.09880861639976501, 0.019906116649508476, 0.12366307526826859, 0.054130952805280685, 0.010116703808307648, 0.004378759767860174], [0.042106740176677704, 0.03533118963241577, 0.056240931153297424, 0.03206101432442665, 0.07143910974264145, 0.01964769884943962, 0.05548941716551781, 0.08988051116466522, 0.023817934095859528, 0.015511749312281609, 0.09527423977851868, 0.025800324976444244, 0.026004470884799957, 0.09507463127374649, 0.02868751436471939, 0.05399225652217865, 0.023596009239554405,